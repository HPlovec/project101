# -*- coding: utf-8 -*-
"""Project101.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X7lyHU1xxcYUDF72D9AI5-C_fi96OAFI
"""

#Training the model from the data set

import pandas as pd
#for data manipulation and analysis. It's used here to load the customer
#support ticket data from a CSV file into a DataFrame, which is a tabular data structure that makes it easy to work with the data.
import numpy as np
# NumPy is a fundamental library for numerical computing in Python.
#It's used for working with arrays and performing mathematical operations efficiently, which is common in machine learning tasks.
from sklearn.model_selection import train_test_split
#This module from scikit-learn is used to split the dataset into training and testing sets.
#This is a crucial step in machine learning to evaluate how well a model generalizes to unseen data.
from sklearn.pipeline import Pipeline
#The Pipeline class from scikit-learn is used to chain together multiple processing steps (like text vectorization and classification)
#into a single object.
#This simplifies the workflow and ensures that the same steps are applied consistently.
from sklearn.feature_extraction.text import TfidfVectorizer
#this is used to convert the raw text data into numerical features using the TF-IDF method.
from sklearn.tree import DecisionTreeClassifier
#This imports the Decision Tree classifier algorithm from scikit-learn.
#It's one of the models being trained to categorize the tickets.
from sklearn.ensemble import RandomForestClassifier
#another model being used for categorization. Random Forest is an ensemble method that uses multiple decision trees.
from sklearn.linear_model import LogisticRegression
#This imports the Logistic Regression classifier algorithm, the third model used for categorization.
#It's a linear model commonly used for binary and multi-class classification.
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
#These functions from scikit-learn are used to evaluate the performance of the classification models.
#classification_report: Provides metrics like precision, recall, and F1-score for each class.
#confusion_matrix: Shows a table summarizing the correct and incorrect predictions for each class.
#from sklearn.preprocessing import LabelEncoder: While imported, LabelEncoder is not directly
#used in the final version of the provided code, but it's typically used to convert
#categorical text labels into numerical labels that machine learning models can work with.
import re
#The re module provides support for regular expressions, which are used in the rule-based
#severity classification system to find specific patterns and keywords in the text.
from typing import Dict, List, Tuple
#These are used for type hinting, which helps improve code readability and allows for static
#analysis to catch potential type-related errors. Dict, List, and Tuple specify that variables
#are expected to be dictionaries, lists, and tuples, respectively.

# complaint_severity.py
# severity classifier (rule-based)
HIGH_KEYWORDS = {
    r"\b(fraud|scam|hacked|identity theft)\b": 5,
    r"\b(legal|attorney|lawyer|lawsuit|sue)\b": 6,
    r"\b(unsafe|hazard|injur(?:y|ed)|burned|choked)\b": 8,
    r"\b(chargeback|dispute with bank)\b": 6,
    r"\b(bbb|better business bureau|ftc)\b": 5,
    r"\b(never\s+again|cancel(?:ling)? my account|report this)\b": 4,
}

# Medium indicators
MED_KEYWORDS = {
    r"\b(damaged|broken|defective|missing parts?)\b": 3,
    r"\b(late|delayed|no\s*tracking|lost package)\b": 2,
    r"\b(refund|return|charge[d]?\s*twice)\b": 2,
    r"\b(this is the (2nd|second|3rd|third|fourth) time|again)\b": 2,
    r"\b(unacceptable|outrageous|disgusting)\b": 2,
}

# Low-level friction words
LOW_KEYWORDS = {
    r"\b(please help|frustrated|disappointed)\b": 1,
    r"\b(cannot|can\'t|won\'t|error)\b": 1,
}

# Profanity / hostility can boost severity because it often correlates with urgency
PROFANITY = {
    r"\b(damn|hell|crap)\b": 1,
    r"\b(fuck|shit|bitch|asshole)\b": 3,
}

#weighted signals and keyword patterns used for the rule-based severity classification system.
#Regular expression to detect monetary amounts in text
#Matches patterns like "$100", "50 dollars", "USD 25"
#Used later to boost severity when specific money amounts are mentioned
#It takes two arguments: text (the customer support ticket description as a string)
#It then iterates through each pat (pattern) and w (weight) in the patterns dictionary.
#If a pattern is found in the text, the corresponding weight w is added to the total score s.
MONEY_RE = re.compile(r"(\$|usd|\bdollar[s]?\b)\s*\d+", re.I)

def score_by_patterns(text: str, patterns: Dict[str, int]) -> int:
    s = 0
    for pat, w in patterns.items():
        if re.search(pat, text, flags=re.I):
            s += w
    return s

def punctuation_intensity(text: str) -> int:
    # Exclamation marks + sequences of "!!!" or "???" boost
    excls = text.count("!")
    qmarks = text.count("?")
    bonus = 0
    if "!!!" in text or "???" in text:
        bonus += 2
    return min(3, excls // 2) + min(2, qmarks // 3) + bonus

def caps_intensity(text: str) -> int:
    # ALL-CAPS words can indicate shouting
    words = re.findall(r"[A-Za-z]{3,}", text)
    if not words:
        return 0
    allcaps = sum(1 for w in words if w.isupper())
    ratio = allcaps / max(1, len(words))
    if ratio >= 0.25: # 25%+ caps is a lot
        return 3
    if ratio >= 0.10:
        return 2
    return 0

def money_intensity(text: str) -> int:
    # Mentions of specific dollar amounts raise severity
    #Contains regular expressions that match severe complaint indicators
    #Each pattern has a weight score (4-8 points) - higher scores = more severe
    #Examples: "fraud", "lawsuit", "injury" get high severity scores
    #\b (matches whole words only)
    return 2 if MONEY_RE.search(text) else 0

def time_urgency(text: str) -> int:
    # “today”, “now”, “immediately”, missed deadlines, etc.
    if re.search(r"\b(now|immediately|asap|today|right away|hours not days)\b", text, re.I):
        return 2
    if re.search(r"\b(deadline|by end of (day|week)|now)\b", text, re.I):
        return 1
    return 0
#Minor severity indicators (1 point each)
#Polite requests for help, basic technical issues

def build_severity_score(text: str) -> Tuple[int, Dict[str, int]]:
    """
    Returns (total_score, components) for transparency.
    """
    components = {}
    components["high_keywords"] = score_by_patterns(text, HIGH_KEYWORDS)
    components["med_keywords"] = score_by_patterns(text, MED_KEYWORDS)
    components["low_keywords"] = score_by_patterns(text, LOW_KEYWORDS)
    components["profanity"] = score_by_patterns(text, PROFANITY)
    components["punctuation"] = punctuation_intensity(text)
    components["all_caps"] = caps_intensity(text)
    components["money"] = money_intensity(text)
    components["time_urgency"] = time_urgency(text)


    total = sum(components.values())
    return total, components

def bucket_severity(score: int) -> str:
    """
    Map numeric score to categories.
    """
    if score >= 10:
        return "HIGH"
    if score >= 5:
        return "MEDIUM"
    return "LOW"

def categorize_complaints(complaints: List[str]) -> List[Dict]:
    results = []
    for t in complaints:
        score, parts = build_severity_score(t)
        results.append({
            "text": t,
            "severity": bucket_severity(score),
            "score": score,
            "explain": parts
        })
    # Sort: highest severity first, then by score
    results.sort(key=lambda r: ({"HIGH":2,"MEDIUM":1,"LOW":0}[r["severity"]], r["score"]), reverse=True)
    return results


def load_and_preprocess_data():
    """Load and preprocess the customer support tickets dataset"""
    try:
        # Load the customer support tickets CSV
        df = pd.read_csv("customer support tickets.csv")
        print("Successfully loaded customer support tickets dataset!")
        print(f"Dataset shape: {df.shape}")
        print(f"Columns: {df.columns.tolist()}")

        # Check for tthe required columns
        if 'Ticket Description' not in df.columns or 'Ticket Type' not in df.columns:
            print("Required columns not found. Available columns:", df.columns.tolist())
            return None, None, None, None

        # Clean and preprocess the data
        df = df.dropna(subset=['Ticket Description', 'Ticket Type'])

        # Extract text and labels
        texts = df['Ticket Description'].astype(str).tolist()
        ticket_types = df['Ticket Type'].astype(str).tolist()

        # Map ticket types to our target categories
        type_mapping = {
            'Technical issue': 'complaint',
            'Billing inquiry': 'account_billing',
            'Cancellation request': 'account_billing',
            'Product inquiry': 'shipping',
            'Refund request': 'returns_refunds',
            'Complaint': 'complaint', # Added mapping for 'Complaint' if it exists
            'Shipping': 'shipping', # Added mapping for 'Shipping' if it exists
            'Returns/Refunds': 'returns_refunds', # Added mapping for 'Returns/Refunds' if it exists
            'Account/Billing': 'account_billing', # Added mapping for 'Account/Billing' if it exists
            'Spam': 'spam' # Added mapping for 'Spam' if it exists
        }

        # Apply mapping, keep original if not in mapping
        mapped_types = [type_mapping.get(t, t.lower()) for t in ticket_types]

        # For better accuracy
        for i, text in enumerate(texts):
            text_lower = text.lower()

            # Priority-based classification

            # Check for fraud/scam (highest priority for complaints) Complaint are likly to be spam
            if any(keyword in text_lower for keyword in ['fraud', 'scam', 'lawyer', 'lawsuit', 'legal', 'sue', 'attorney']):
                mapped_types[i] = 'complaint'

            # Check for refund/return keywords
            elif any(keyword in text_lower for keyword in ['refund', 'return', 'exchange', 'damaged', 'defective', 'wrong item', 'doesn\'t fit', 'not as described', 'broken', 'faulty']):
                mapped_types[i] = 'returns_refunds'

            # Check for billing keywords (more specific)
            elif any(keyword in text_lower for keyword in ['charged twice', 'double charge', 'billing', 'payment', 'credit card', 'invoice', 'overcharged', 'wrong charge']):
                mapped_types[i] = 'account_billing'

            # Check for shipping keywords (more specific)
            elif any(keyword in text_lower for keyword in ['shipping', 'delivery', 'tracking', 'address', 'ship', 'package', 'delivery status', 'when will', 'arrived', 'shipment']):
                mapped_types[i] = 'shipping'

            # Check for general complaint keywords (after specific categories)
            elif any(keyword in text_lower for keyword in ['terrible', 'awful', 'unacceptable', 'disappointed', 'frustrated', 'angry', 'worst', 'horrible', 'disgusting']):
                mapped_types[i] = 'complaint'


        # Create severity labels based on text analysis using the moved function
        severity_results = categorize_complaints(texts) # Use the correct function
        #This line calls the categorize_complaints function (which uses the rule-based system you saw earlier)
        #to analyze the texts (the cleaned ticket descriptions) and determine a severity score and level (HIGH, MEDIUM, LOW)
        #for each ticket. The results are stored in the severity_results list.

        #This line extracts just the predicted severity level ('HIGH', 'MEDIUM', or 'LOW') from each result in severity_results and
        #creates a new list called severity_labels. This list will be used as the target variable for training the severity classifier model.
        severity_labels = [result['severity'] for result in severity_results]


        print(f"Loaded {len(texts)} samples")
        #Prints the total number of samples (tickets) successfully loaded and processed.
        print("Category distribution:")
        category_counts = pd.Series(mapped_types).value_counts()
        #These calculate and print the distribution of the mapped ticket categories (mapped_types).
        #It shows how many tickets fall into each category (complaint, shipping, returns_refunds, account_billing).
        #This is useful for understanding the dataset's class balance.
        print(category_counts.to_dict())

        print("Severity distribution:")
        #These calculate and print the distribution of the newly created severity labels

        #This shows how many tickets are classified as HIGH, MEDIUM, or LOW severity based on the rule-based system.
        #This is also important for understanding the distribution of severity levels in the dataset.
        severity_counts = pd.Series(severity_labels).value_counts()
        print(severity_counts.to_dict())

        return texts, mapped_types, severity_labels, df
        #texts: A list of the cleaned ticket descriptions. mapped_types: A list of the mapped category labels for each ticket.
        #severity_labels: A list of the predicted severity labels for each ticket (derived from the rule-based system).
        #df: The pandas DataFrame containing the loaded and cleaned data.


#Instead of the program crashing when an error happens, it catches the error, prints a helpful message indicating that data
#loading failed, and returns None for all the expected outputs.
    except Exception as e:
        print(f"Error loading dataset: {e}")
#except Exception as e:: This line indicates that if any type of error (Exception) occurs within the corresponding try block above it,
#the code inside this except block will be executed. The error object is assigned to the variable e,
#which allows you to access information about the error.

#return None, None, None, None: This line is executed after printing the error message. It causes the load_and_preprocess_data function to
#stop its execution and return four None values.
        return None, None, None, None

def train_category_classifier(texts: List[str], categories: List[str]):
    """Train a classifier for email categorization"""
    print("\n=== TRAINING CATEGORY CLASSIFIER ===")

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        texts, categories, test_size=0.2, random_state=42, stratify=categories
    )

    # Create and train multiple models so the best can be found
    models = {
        'Decision Tree': Pipeline([
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
            ('classifier', DecisionTreeClassifier(max_depth=20, random_state=42))
        ]),
        'Random Forest': Pipeline([
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
        ]),
        'Logistic Regression': Pipeline([
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
            ('classifier', LogisticRegression(max_iter=1000, random_state=42))
        ])
    }

    best_model = None
    best_score = 0
    best_model_name = ""

    for name, model in models.items():
        print(f"\nTraining {name}...")

        # Create validation split for early stopping. Using a validation set helps in selecting the best model
        #among the different algorithms (Decision Tree, Random Forest, Logistic Regression) because the evaluation
        #is done on data the models haven't been directly trained on, providing a more
        #realistic estimate of how they will perform on new data.
        X_train_split, X_val, y_train_split, y_val = train_test_split(
            X_train, y_train, test_size=0.2, random_state=42
        )

        best_val_score = 0
        patience = 5
        patience_counter = 0

        # Early stopping for Logistic Regression
        #tfidf convert text data into numerical
        #classifier learns patterns and features in the data for new data
        if 'Logistic' in name:
            for max_iter in [100, 200, 500, 1000, 2000]:
                temp_model = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
                    ('classifier', LogisticRegression(max_iter=max_iter, random_state=42))
                ])
                temp_model.fit(X_train_split, y_train_split)
                val_pred = temp_model.predict(X_val)
                val_score = np.mean(val_pred == y_val)

                if val_score > best_val_score:
                    best_val_score = val_score
                    model = temp_model
                    patience_counter = 0
                else:
                    patience_counter += 1

                if patience_counter >= patience:
                    print(f"Early stopping at max_iter={max_iter}")
                    break

        # Early stopping for Random Forest
        #checks if the current model being trained in the outer loop is the Random Forest classifier.
        elif 'Random Forest' in name:
            for n_estimators in [10, 25, 50, 100, 200, 300]: #Trying out different numbers of trees to see which performs best.
                temp_model = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
                    ('classifier', RandomForestClassifier(n_estimators=n_estimators, random_state=42))
                ])
                temp_model.fit(X_train_split, y_train_split)
                val_pred = temp_model.predict(X_val)
                val_score = np.mean(val_pred == y_val)

                if val_score > best_val_score:
                    best_val_score = val_score
                    model = temp_model
                    patience_counter = 0
                else:
                    patience_counter += 1

                if patience_counter >= patience:
                    print(f"Early stopping at n_estimators={n_estimators}")
                    break

        # Early stopping for Decision Tree
        elif 'Decision Tree' in name:
            for max_depth in [5, 10, 15, 20, 25, 30]:
                temp_model = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),
                    ('classifier', DecisionTreeClassifier(max_depth=max_depth, random_state=42))
                ])
                temp_model.fit(X_train_split, y_train_split)
                val_pred = temp_model.predict(X_val)
                val_score = np.mean(val_pred == y_val)

                if val_score > best_val_score:
                    best_val_score = val_score
                    model = temp_model
                    patience_counter = 0
                else:
                    patience_counter += 1

                if patience_counter >= patience:
                    print(f"Early stopping at max_depth={max_depth}")
                    break
        else:
            # For models without early stopping, just train normally
            model.fit(X_train, y_train)

        # Evaluate
        y_pred = model.predict(X_test)
        #This line uses the currently trained model to make predictions on the X_test dataset.
        #X_test contains the ticket descriptions that the model hasnot seen during training. The predictions are stored in the y_pred variable.
        accuracy = np.mean(y_pred == y_test)
        #This calculates the accuracy of the model's predictions. It compares the predicted labels (y_pred) with the actual true labels (y_test)
        #for the test set. y_test contains the correct categories for the tickets in X_test. y_pred == y_test creates a boolean array where True
        #indicates a correct prediction and False indicates an incorrect one. np.mean() then calculates the average of this boolean array, which
        #is the proportion of correct predictions, i.e., the accuracy.
        print(f"{name} Accuracy: {accuracy:.4f}")
        #This line prints the accuracy score for the current model (name refers to the model name like 'Decision Tree', 'Random Forest', etc.),
        #formatted to four decimal places.
        print(f"{name} Classification Report:")
        print(classification_report(y_test, y_pred, zero_division=0))

        if accuracy > best_score:
            best_score = accuracy
            best_model = model
            best_model_name = name
      #If the current model has a higher accuracy, its accuracy becomes the new best_score, the model itself is stored in best_model, and its name is
      #stored in best_model_name.

    if best_model is None:
        print("No models were successfully trained!")
        return None, None, None

    print(f"\nBest model: {best_model_name} with accuracy: {best_score:.4f}")
    return best_model, X_test, y_test

def train_severity_classifier(texts: List[str], severities: List[str]):
    """Train a classifier for severity prediction"""
    print("\n=== TRAINING SEVERITY CLASSIFIER ===")

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        texts, severities, test_size=0.2, random_state=42, stratify=severities
    )

    # Create validation split for early stopping
    X_train_split, X_val, y_train_split, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )

    # Early stopping for severity classifier
    best_val_score = 0
    patience = 5
    patience_counter = 0
    severity_pipeline = None

    for n_estimators in [25, 50, 100, 150, 200, 300]:
        temp_model = Pipeline([
            ('tfidf', TfidfVectorizer(
                max_features=3000,
                ngram_range=(1, 3),
                stop_words='english',
                token_pattern=r'\b[A-Za-z]{2,}|!+|\?+|[A-Z]{2,}'
            )),
            ('classifier', RandomForestClassifier(n_estimators=n_estimators, random_state=42))
        ])

        temp_model.fit(X_train_split, y_train_split)
        val_pred = temp_model.predict(X_val)
        val_score = np.mean(val_pred == y_val)

        if val_score > best_val_score:
            best_val_score = val_score
            severity_pipeline = temp_model
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print(f"Early stopping for severity at n_estimators={n_estimators}")
            break

    # Evaluate
    y_pred = severity_pipeline.predict(X_test)
    accuracy = np.mean(y_pred == y_test)

    print(f"Severity Classifier Accuracy: {accuracy:.4f}")
    print("Severity Classification Report:")
    print(classification_report(y_test, y_pred, zero_division=0))

    return severity_pipeline, X_test, y_test

def demonstrate_predictions(category_model, severity_model, sample_texts: List[str]):
    """Demonstrate predictions on sample texts"""
    print("\n=== PREDICTION DEMONSTRATIONS ===")

    for text in sample_texts: #This loop iterates through each individual text string in the sample_texts list
        category_pred = category_model.predict([text])[0]
        severity_pred = severity_model.predict([text])[0]

        # Get prediction probabilities if available
        try:
            category_proba = category_model.predict_proba([text])[0] #If the category model supports it, this gets
            #the probability of the text belonging to each possible category.
            category_classes = category_model.classes_ #This gets the list of all possible category labels the model can predict
            category_confidence = max(category_proba) #This finds the highest probability among all categories for the predicted category

            severity_proba = severity_model.predict_proba([text])[0]
            severity_classes = severity_model.classes_
            severity_confidence = max(severity_proba)

            print(f"\nText: {text[:100]}...")
            print(f"Category: {category_pred} (confidence: {category_confidence:.3f})")
            print(f"Severity: {severity_pred} (confidence: {severity_confidence:.3f})")

        except:
            print(f"\nText: {text[:100]}...")
            print(f"Category: {category_pred}")
            print(f"Severity: {severity_pred}")

if __name__ == "__main__":
    print("=== CUSTOMER SUPPORT TICKET ML TRAINING ===")

    # Load and preprocess data
    texts, categories, severities, df = load_and_preprocess_data()

    if texts is None:
        print("Failed to load data. Exiting.")
        exit(1)

    # Train category classifier
    category_model, cat_X_test, cat_y_test = train_category_classifier(texts, categories)

    if category_model is None:
        print("Failed to train category classifier. Exiting.")
        exit(1)

    # Train severity classifier
    severity_model, sev_X_test, sev_y_test = train_severity_classifier(texts, severities)

    if severity_model is None:
        print("Failed to train severity classifier. Exiting.")
        exit(1)

    # Sample texts for demonstration and testing
    demo_texts = [
        "URGENT: My package is damaged and I need a refund immediately! This is unacceptable!",
        "I have a question about my shipping address, can you help me update it?",
        "I'd like to return this item please, it doesn't fit properly",
        "My credit card was charged twice for the same order, please fix this",
        "FRAUD! This company is a scam! I'm calling my lawyer!",
        "The product arrived on time but I have a small question about setup"
    ]

    # Demonstrate predictions
    #importances[i] is an array containing the importance score for each word or phrase)
    #learned by the category classifier.np.argsort(importances) returns the indices that would
    #sort the importances array in ascending order.[-20:] slices this array of indices to get the last 20 indices.

    print("\nDemonstrate Predictions")
    demonstrate_predictions(category_model, severity_model, demo_texts)


    if hasattr(category_model.named_steps['classifier'], 'feature_importances_'):
        print("\n=== CATEGORY MODEL FEATURE IMPORTANCE ===")
        feature_names = category_model.named_steps['tfidf'].get_feature_names_out()
        importances = category_model.named_steps['classifier'].feature_importances_

        # Get top 20 most important words or phrases
        top_indices = np.argsort(importances)[-20:]
        top_features = [(feature_names[i], importances[i]) for i in top_indices]
        top_features.reverse()

        print("Top 20 most important word or phrase for categorization:")
        for feature, importance in top_features:
            print(f"{feature}: {importance:.4f}")

    print("\n=== TRAINING COMPLETE ===")
    print("Models are ready for categorizing emails into:")
    print("Categories: complaint, shipping, returns_refunds, account_billing")
    print("Severity Levels: HIGH, MEDIUM, LOW")

#This helps customer support teams by:
#Automatically sort customer support tickets into categories (like "billing", "shipping", "complaints") and assign severity levels
 #("HIGH", "MEDIUM", "LOW") to help support teams prioritize their work.
#Automatically routing tickets to the right department
#Prioritizing urgent issues (fraud, legal threats)
#Reducing response time for critical problems
#Improving customer satisfaction through faster, more accurate handling
#The code essentially creates an intelligent triage system for customer support, making sure the most important issues get attention first
#while organizing everything efficiently.
#Uses 3 different ML models (Decision Tree, Random Forest, Logistic Regression)
#Analyzes ticket text to predict categories: complaint, shipping, returns_refunds, account_billing
#Picks the best-performing model automatically!How does the machine learning know which is the best to switch to?
#Each model is trained on the same training data
#Each model is tested on the same test data
#The code calculates accuracy scores for each model
#The model with the highest accuracy automatically becomes the "best_model"
#This best-performing model is then returned and used for all future predictions
#Transparent process - prints each model's performance so you can see the comparison
#One-time selection - once chosen, that model handles all category predictions
#The code essentially runs a mini-competition between the three algorithms and automatically picks
#the winner based on which one performs best on your specific customer support ticket data.
#Create a validation, f1 model, classification metrics, where shoul we use early stopping?